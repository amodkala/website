---
key: 7
title: "Log-Structured Storage"
source: "Database Internals"
relatedNotes:
- ddia-ch-3
---

{frontmatter.source}
# {frontmatter.title}

## LSM-Trees

B-Trees and LSM-Trees are examples of mutable and immutable data structures,
respectively. An update operation on a B-Tree involves overwriting the record on
disk, while updating an LSM-Tree first inserts a new record before eventually
reconciling the change. Read operations are more efficient on mutable data
structures as once the record is located on disk its value can be returned to
the client. Contrast this with immutable data structures, which requires
processing of every occurence of the record in order to produce the most recent
key. Write operations, on the other hand, favour immutable data structures.
LSM-Trees insert records into a balanced and sorted memtable which flushes
records to the disk (via SSTables) in the background. The initial write
operation is complex than for the B-Tree, which must traverse its structure to
write the new record to the appropriate location on disk, rebalancing itself and
rewriting pages as necessary.

The LSM-Tree's memory-resident component (also called the memtable) is a mutable
buffer which serves as the first target for read and write operations. It is
usually implemented as a sorted tree which facilitates concurrent access, and is
accompanied by a write-ahead log (WAL) for recovery purposes. Once the memtable
exceeds a specified size, its contents are flushed to files on disk which are
only accessed during read, merge, and file removal operations. Once flushed, the
segment of the WAL containing the records stored by that memtable can be
discarded.

The multicomponent LSM-Tree is one where memtables are flushed in their entirety
as individual disk-resident tables. To avoid accessing multiple files per read
operation, we periodically compact select tables by aggregating them into a new
file and discarding the old tables.

Deleting a record requires the use of a tombstone, which acts as a flag to
remove all instances of the key during the reconciliation process.

Due to their immutability, LSM-Trees may contain different versions of data
across their multiple components (memory-resident and disk-resident tables),
which necessitates a merge-and-reconcile strategy for performing lookups.

Merge-iteration takes advantage of the fact that memory-resident and
disk-resident tables are all sorted to iterate across all sources at once.
Iterators for each source are loaded into a priority queue implementation such
as a min-heap, which maintains this cascade of invariants. In the event that
there are multiple values for a given key, we use metadata such as timestamps to
determine which record should be returned to the client or written during
compaction.

Compaction is the maintenance process for LSM-Trees which reconciles duplicated
and tombstoned/deleted keys, reducing disk usage by the disk-resident tables.

Leveled compaction organizes disk-resident tables into "levels", with target
table sizes and number of tables per level. Compaction occurs as follows:
- Level 0 consists solely of flushed memtables
- Once a level exceeds its target number of tables, each of its tables are
  partitioned according to the key ranges of the proceeding level's tables and
  merged with the appropriate tables there.
As each successive layer holds tables exponentially larger than those on the
preceeding layer, older data gradually makes its way into higher levels.

## Read, Write, and Space Amplification

There are certain tradeoffs to be considered when adopting a strategy for the
compaction of immutable records. Read amplification is the result of searching
multiple data structures containing the same key to determine the most recent
value. Write amplification arises from frequent compaction in an attempt to
reduce the number of duplicate records.

## Implementation Details

Sorted String Tables (SSTables) are the data structures used to implement
disk-resident storage. They consist of index files (which are themselves
implemented as B-Trees or hash tables) and data files, where the location of a
record (its offset) within the datafile is what is indexed in the index file

Bloom filters are probabilistic data structures which report either that an item
is probably in a set, or it is definitely not in the set. The application to
SSTables in the context of read amplification is obvious, as only those files
which might contain the target key will be read during the merge-iteration
process. Implementation-wise, we use a bit array along with hash functions 
(larger bit arrays reduce the likelihood of hash collisions) as follows:
- Keys in the SSTable are hashed to produce indices of the bit array, which are
  set to 1
- Depending on the length of the bit array, the indices produced by the hash of
  one key could also be produced by one or multiple other unique keys (hash
  collision)
- On lookup, we use the hash function to produce the bit array indices of
  interest, and for each bloom filter where all of these bits are set we add the
  corresponding SSTable to our merge-iterator.
- If any bit array index produced by a key's hash is 0, then it must not be in
  that SSTable, but if all the bits are 1 then the key might be in the SSTable.
